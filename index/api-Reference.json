[
  {
    "title": "API Reference",
    "id": "introduction",
    "mainUrl": "/docs/api-reference/introduction",
    "sections": [
      {
        "title": "API Interaction",
        "id": "api-interaction",
        "contents": [
          "You can interact with the API through HTTP or WebSocket requests from any programming language.",
          "Official Python bindings are available for easy integration.",
          "Official Node.js libraries are provided for JavaScript and TypeScript applications."
        ]
      },
      {
        "title": "Python SDK",
        "id": "python-sdk-install",
        "contents": [
          "Install the official Python bindings using pip.",
          "The Python SDK provides a simple interface for API integration."
        ]
      },
      {
        "title": "Node.js SDK",
        "id": "nodejs-sdk-install",
        "contents": [
          "Install the official Node.js library in your project directory.",
          "The Node.js SDK supports both JavaScript and TypeScript applications."
        ]
      }
    ]
  },
  {
    "title": "Authentication",
    "id": "authentication",
    "mainUrl": "/docs/api-reference/authentication",
    "sections": [
      {
        "title": "API Keys",
        "id": "api-keys",
        "contents": [
          "The API uses API key authentication to secure access to all endpoints.",
          "You must include a valid API key in every request to authenticate your identity.",
          "API keys ensure authorized access to the platform."
        ]
      },
      {
        "title": "Obtain API Key",
        "id": "obtain-api-key",
        "contents": [
          "Register for an account to obtain an API key.",
          "Navigate to the API Keys section in your dashboard.",
          "Generate and manage your API keys from the dashboard."
        ]
      },
      {
        "title": "Authenticated Requests",
        "id": "authenticated-requests",
        "contents": [
          "Include your API key in the X-API-Key header for all requests.",
          "The X-API-Key header format ensures proper authentication."
        ]
      },
      {
        "title": "Python SDK Authentication",
        "id": "auth-python-sdk",
        "contents": [
          "Initialize the Alle-AI Python client with your API key.",
          "The Python SDK handles authentication automatically once configured."
        ]
      },
      {
        "title": "Node.js SDK Authentication",
        "id": "auth-nodejs",
        "contents": [
          "Initialize the Alle-AI Node.js client with your API key.",
          "The Node.js SDK manages authentication seamlessly after setup."
        ]
      }
    ]
  },
  {
    "title": "SDK Best Practices",
    "id": "sdk",
    "mainUrl": "/docs/api-reference/sdk",
    "sections": [
      {
        "title": "Python SDK",
        "id": "python-sdk-api",
        "contents": [
          "The official Alleai Python SDK provides a simple and intuitive interface.",
          "Use the Python SDK for easy API integration in Python applications."
        ]
      },
      {
        "title": "Node.js SDK",
        "id": "nodejs-sdk-api",
        "contents": [
          "The official Alleai Node.js SDK is built for modern JavaScript and TypeScript applications.",
          "Supports both CommonJS and ES modules for flexible integration."
        ]
      },
      {
        "title": "Best Practices",
        "id": "best-practice-sdk",
        "contents": [
          "Store your API key in environment variables to keep it secure.",
          "Avoid hardcoding API keys in your application code.",
          "Always wrap API calls in try-catch blocks to handle errors gracefully.",
          "Use TypeScript for better type safety and autocompletion when using Node.js.",
          "Regularly update the SDKs to benefit from the latest features and bug fixes.",
          "Implement proper error handling for production applications."
        ]
      }
    ]
  },
  {
    "title": "Chat Completion",
    "id": "chat-endpoints",
    "mainUrl": "/docs/api-reference/chat-endpoints",
    "sections": [
      {
        "title": "Chat Completion Overview",
        "id": "chat-completion",
        "contents": [
          "The Chat Completion endpoint is a unified gateway to multiple AI models.",
          "Access ChatGPT, Claude, Gemini, and more through a single endpoint.",
          "Generate human-like text responses using state-of-the-art language models.",
          "Choose from OpenAI's ChatGPT (GPT-3.5, GPT-4), Anthropic's Claude, and Google's Gemini."
        ]
      },
      {
        "title": "Endpoint URL",
        "id": "chat-completion-endpoint",
        "contents": [
          "All chat completion API requests should be made using HTTPS.",
          "Use the designated completion endpoint URL for all requests."
        ]
      },
      {
        "title": "Request Parameters",
        "id": "completion-params",
        "contents": [
          "Specify AI model names like gpt-4, deepseek-1, or claude-3.5-sonnet in your request.",
          "Include system instructions to guide the model's behavior and set its role or tone.",
          "Provide user inputs such as text questions, audio recordings, images, or videos.",
          "Include prior assistant responses organized by model name to maintain conversation flow.",
          "Messages can contain text, audio URLs, image URLs, or video URLs for flexible communication.",
          "Control output format by specifying text, audio URL, image URL, or video URL responses.",
          "Set different response formats for specific models when using multiple models.",
          "Enable web search with true to include up-to-date information in responses.",
          "Disable web search with false to rely only on the model's existing knowledge.",
          "Configure summary format as text, audio URL, image URL, or video URL.",
          "Select which models should create the summary for customized insights.",
          "Set up response merging from multiple models into one cohesive output.",
          "Define merge format and select which models' answers to blend together.",
          "Adjust temperature for creativity - use lower values (0.1) for focused answers.",
          "Use higher temperature values (up to 1.0) for more imaginative responses.",
          "Set max_tokens to cap response length measured in words or characters.",
          "Control response variety with top_p - lower values (0.5) keep answers focused.",
          "Higher top_p values (up to 1.0) allow models to explore wider possibilities.",
          "Use repetition_penalty (up to 2.0) to reduce repetition and keep content fresh.",
          "Lower or negative repetition_penalty values allow more repetition if desired.",
          "Adjust presence_penalty to influence new topics vs. current discussion focus.",
          "Higher presence_penalty (up to 2.0) encourages fresh ideas and topics.",
          "Enable streaming with true to get responses as they're being created.",
          "Disable streaming with false to receive complete responses all at once.",
          "Use model_params to fine-tune settings for individual models.",
          "Override general options with model-specific system instructions and creativity levels."
        ]
      },
      {
        "title": "Request Headers",
        "id": "request-headers-chat",
        "contents": [
          "Include proper request headers for API authentication and content type.",
          "Set Content-Type to application/json for JSON request bodies."
        ]
      },
      {
        "title": "Response Format",
        "id": "response-format-chat",
        "contents": [
          "API responses include a success indicator for request status.",
          "Response data contains a unique identifier for each response.",
          "Object type is returned as ai.completions for chat responses.",
          "Creation timestamp includes date, time, and timezone information.",
          "Model list shows all models used in the API call.",
          "Response content is organized by model name for easy access.",
          "Each model response includes the model name and generated content.",
          "Stop reason indicates why the response ended (e.g., stop, STOP).",
          "Token usage details are provided for each model response.",
          "API usage information includes total requests made and associated costs.",
          "Cost breakdown shows input token costs, output token costs, and total usage cost."
        ]
      }
    ]
  },
  {
    "title": "Web Search",
    "id": "chat-search",
    "mainUrl": "/docs/api-reference/chat-search",
    "sections": [
      {
        "title": "Web Search in Completions",
        "id": "web-search-completions",
        "contents": [
          "Enable web search in completion endpoints by setting web_search parameter to true.",
          "Models can access current information from the web to enhance responses."
        ]
      },
      {
        "title": "Web Search Response",
        "id": "web-search-response",
        "contents": [
          "Responses include web_search_results field when web search is enabled.",
          "Web search results contain information gathered by models during response generation.",
          "Search results enhance model responses with up-to-date information."
        ]
      },
      {
        "title": "Dedicated Web Search Endpoints",
        "id": "web-search-endpoint",
        "contents": [
          "Dedicated web search endpoints are available for specialized search operations.",
          "Use dedicated endpoints for focused web search functionality."
        ]
      }
    ]
  },
  {
    "title": "Model Comparison",
    "id": "chat-comparison",
    "mainUrl": "/docs/api-reference/chat-comparison",
    "sections": [
      {
        "title": "Compare Model Responses",
        "id": "compare-models",
        "contents": [
          "Compare outputs across different AI models using the comparison parameter.",
          "Model comparison helps evaluate different approaches to the same query."
        ]
      },
      {
        "title": "Comparison Configuration",
        "id": "model-output-compare",
        "contents": [
          "The comparison field is optional and enables cross-model comparisons.",
          "Omitting the comparison field returns only standard model outputs.",
          "Include comparison field with an array of comparison objects.",
          "Each comparison object defines a specific comparison type and models.",
          "Supported comparison types include text and audio_url comparisons.",
          "Text type compares text outputs from specified models.",
          "Audio_url type compares audio content from provided URLs.",
          "Models field accepts arrays of model combination strings.",
          "Combine models using plus signs (+) for ensemble comparisons.",
          "Example: gpt-4o+deepseek-r1+claude-3.5-sonnet for multi-model comparison.",
          "Each string represents a distinct set of models used together.",
          "Multiple model combination strings enable different comparison scenarios."
        ]
      }
    ]
  },
  {
    "title": "Response Summarization",
    "id": "chat-summary",
    "mainUrl": "/docs/api-reference/chat-summary",
    "sections": [
      {
        "title": "Summary in Completions",
        "id": "summary-completion",
        "contents": [
          "Include summary configuration in completion endpoint requests.",
          "Summarization condenses multiple model responses into key insights."
        ]
      },
      {
        "title": "Dedicated Summary Endpoints",
        "id": "summary-endpoints",
        "contents": [
          "Use dedicated summary endpoints at baseUrl/summary for streamlined summaries.",
          "Summary endpoints focus solely on delivering summary results without individual model outputs.",
          "Configure summary requests using messages for queries and response_format for output type.",
          "Adjust summary behavior with settings like temperature for fine-tuning.",
          "Summary endpoints provide lightweight, essential insights without extra detail."
        ]
      }
    ]
  },
  {
    "title": "Response Combination",
    "id": "chat-combination",
    "mainUrl": "/docs/api-reference/chat-combination",
    "sections": [
      {
        "title": "Combinations in Completions",
        "id": "combination-completion",
        "contents": [
          "Configure response combinations in completion endpoint requests.",
          "Combine multiple model responses into a single cohesive output."
        ]
      },
      {
        "title": "Dedicated Combination Endpoints",
        "id": "combination-endpoints",
        "contents": [
          "Use dedicated combination endpoints at baseUrl/combinations for focused results.",
          "Combination endpoints skip individual model outputs and deliver only combined results.",
          "Configure requests with messages for queries and response_format for output style.",
          "Use temperature and other parameters for fine-tuning combined responses.",
          "Specify model combinations using the + notation in the combination array.",
          "Example: type: text, models: gpt-4o+deepseek-r1+claude-3.5-sonnet.",
          "Get synthesized outputs without raw model-by-model breakdowns."
        ]
      }
    ]
  },
  {
    "title": "Image Generation",
    "id": "image-generation",
    "mainUrl": "/docs/api-reference/image-generation",
    "sections": [
      {
        "title": "Image Generation Overview",
        "id": "image-generation-api",
        "contents": [
          "Multi-Model Image Generation API leverages multiple AI models simultaneously.",
          "Compare outputs across different models for diverse creative options.",
          "Select the best result for your specific use case from multiple generations.",
          "Supports text-to-image generation from text prompts across multiple models.",
          "Supports image editing to modify existing images using text instructions.",
          "Authentication required using API key for all image generation requests.",
          "Obtain API key by registering for an account and accessing the API Keys dashboard section."
        ]
      }
    ]
  },
  {
    "title": "Text-to-Image",
    "id": "text-to-image",
    "mainUrl": "/docs/api-reference/text-to-image",
    "sections": [
      {
        "title": "Text-to-Image API",
        "id": "text-to-image-api",
        "contents": [
          "Transform text descriptions into visual imagery using multiple AI models simultaneously.",
          "Compare stylistic differences between different image generation models.",
          "Offer diverse creative options to users with multiple model outputs.",
          "Experiment with prompt engineering across different model architectures.",
          "Select the most suitable image output for specific needs and requirements.",
          "Specify an array of selected image models for the API call.",
          "Provide a text description of the desired image or images.",
          "Set the number of images to generate (optional parameter).",
          "Define image height in pixels (optional parameter).",
          "Define image width in pixels (optional parameter).",
          "Use seed value for reproducible image generation (optional parameter).",
          "Specify the style of the generated image (optional parameter)."
        ]
      }
    ]
  },
  {
    "title": "Image Editing",
    "id": "image-generation-edits",
    "mainUrl": "/docs/api-reference/image-generation-edits",
    "sections": [
      {
        "title": "Image Editing API",
        "id": "image-edits-api",
        "contents": [
          "Create, edit, or extend images given an original image and a prompt.",
          "Specify an array of models to use for image editing operations.",
          "Provide image as base64-encoded string or web URL pointing to the image.",
          "Include a text description of the desired edit with maximum length of 1000 characters."
        ]
      }
    ]
  },
  {
    "title": "Audio Generation",
    "id": "audio-text-to-speech",
    "mainUrl": "/docs/api-reference/audio-text-to-speech",
    "sections": [
      {
        "title": "Audio API Overview",
        "id": "audio-generation-api",
        "contents": [
          "Turn audio into text or text into audio by combining multiple audio models.",
          "Create speech by generating audio from input text.",
          "Create transcription by transcribing audio into the input language.",
          "Generate sounds, music, and other audio formats from text descriptions.",
          "Combine the power of multiple audio models for enhanced results.",
          "Authentication required using API key for all audio generation requests.",
          "Obtain API key by registering for an account and accessing the API Keys dashboard section."
        ]
      }
    ]
  },
  {
    "title": "Text-to-Speech",
    "id": "text-to-speech",
    "mainUrl": "/docs/api-reference/text-to-speech",
    "sections": [
      {
        "title": "Text-to-Speech API",
        "id": "text-to-speech-api",
        "contents": [
          "Generate audio from input text using multiple audio models.",
          "Specify an array of selected audio models for text-to-speech conversion.",
          "Provide the text content to generate audio for.",
          "Select the voice to use for audio generation (optional parameter).",
          "Configure model-specific parameters for customized audio generation."
        ]
      }
    ]
  },
  {
    "title": "Speech-to-Text",
    "id": "audio-speech-to-text",
    "mainUrl": "/docs/api-reference/audio-speech-to-text",
    "sections": [
      {
        "title": "Speech-to-Text API",
        "id": "speech-to-text-api",
        "contents": [
          "Create transcription by transcribing audio into the input language.",
          "Specify an array of selected models for audio transcription.",
          "Provide file path or web URL pointing to the audio file to transcribe.",
          "Supported audio formats include flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, and webm.",
          "Configure model-specific parameters for customized audio transcription."
        ]
      }
    ]
  },
  {
    "title": "Audio Generation",
    "id": "audio-generate",
    "mainUrl": "/docs/api-reference/audio-generate",
    "sections": [
      {
        "title": "Audio Generation API",
        "id": "audio-generate-api",
        "contents": [
          "Generate all kinds of sound from supported AI models.",
          "Specify an array of selected audio models for generating audio from text.",
          "Provide text description to generate audio from with maximum length of 4096 characters.",
          "Set the duration of generated audio in seconds (optional parameter).",
          "Configure tempo of generated audio in beats per minute (BPM) (optional parameter).",
          "Specify musical genre for generated audio such as jazz or rock (optional parameter).",
          "Include array of instruments like piano or drums (optional parameter).",
          "Set audio quality as standard or hd with standard as default (optional parameter).",
          "Choose audio output format from mp3, wav, or ogg (optional parameter).",
          "Enable loopable audio generation (optional parameter).",
          "Set the mood of generated audio such as happy or calm (optional parameter).",
          "Configure volume level of generated audio (optional parameter)."
        ]
      }
    ]
  },
  {
    "title": "Text-to-Video",
    "id": "video-generation",
    "mainUrl": "/docs/api-reference/video-generation",
    "sections": [
      {
        "title": "Text-to-Video API",
        "id": "text-to-video-api",
        "contents": [
          "Generate videos from input text using multiple video models.",
          "Specify an array of selected models for generating video from text.",
          "Provide text description to generate video from with maximum length of 4096 characters.",
          "Set the duration of generated video in seconds (optional parameter).",
          "Configure whether the video should loop playback (optional parameter).",
          "Set the aspect ratio of video such as 16:9 or 4:3 (optional parameter).",
          "Configure frame rate of video in frames per second (optional parameter).",
          "Set pixel dimensions of video such as 1280x720 (optional parameter).",
          "Configure resolution quality of video such as 720p (optional parameter).",
          "Use seed value for reproducible video generation (optional parameter).",
          "Include additional parameters specific to selected models (optional parameter).",
          "Video generation is an asynchronous process that may take time to complete.",
          "API responds immediately with job_id or request_id when request is submitted.",
          "Use request_id to poll the status of video generation with GET requests.",
          "Status endpoint returns current job state such as InProgress or Completed.",
          "Completed jobs include generated video URL and related metadata in response.",
          "Asynchronous approach allows efficient management of long-running video generation tasks."
        ]
      }
    ]
  }
]
